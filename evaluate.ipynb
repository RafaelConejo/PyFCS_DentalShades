{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = os.getcwd()  # Current directory\n",
    "pyfcs_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "\n",
    "# Add the PyFCS path to sys.path\n",
    "sys.path.append(pyfcs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1. Human Validation Software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dictionary with the excel that contains the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sheets: ['MariaTejada']\n"
     ]
    }
   ],
   "source": [
    "# Define the Excel file path\n",
    "file_path = os.path.join(os.getcwd(), \"Results\", \"Val_Results.xlsx\")\n",
    "\n",
    "# Load all sheets into a dictionary\n",
    "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Convert each sheet into a DataFrame and store it in a dictionary\n",
    "data_dict = {name: df for name, df in sheets_dict.items()}\n",
    "\n",
    "# Display the loaded sheet names\n",
    "print(f\"Loaded sheets: {list(data_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process human results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sheet: MariaTejada\n"
     ]
    }
   ],
   "source": [
    "def clean_values_confidence(values, confidence):\n",
    "    \"\"\" \n",
    "    Cleans, synchronizes, and sorts Value and Confidence lists, ensuring the highest confidence value is first. \n",
    "    \"\"\"\n",
    "    # Convert values to lists, handling NaN cases safely\n",
    "    values_list = str(values).split(\",\") if pd.notna(values) else []\n",
    "    confidence_list = str(confidence).split(\",\") if pd.notna(confidence) else []\n",
    "\n",
    "    # Trim whitespace and convert confidence to float\n",
    "    values_list = [v.strip() for v in values_list]\n",
    "    confidence_list = [float(c.strip()) for c in confidence_list if c.strip()]\n",
    "\n",
    "    # Ensure both lists have the same length by padding with empty strings or zeros\n",
    "    max_length = max(len(values_list), len(confidence_list))\n",
    "    values_list += [\"\"] * (max_length - len(values_list))\n",
    "    confidence_list += [0.0] * (max_length - len(confidence_list))\n",
    "\n",
    "    # Filter out empty values and confidence scores <= 0\n",
    "    cleaned_pairs = [(v, c) for v, c in zip(values_list, confidence_list) if v and c > 0]\n",
    "\n",
    "    # **Sort by confidence in descending order** (ensures highest confidence value is first)\n",
    "    cleaned_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Separate cleaned values back into lists\n",
    "    cleaned_values = [v for v, _ in cleaned_pairs]\n",
    "    cleaned_confidence = [c for _, c in cleaned_pairs]\n",
    "\n",
    "    return \", \".join(cleaned_values), \", \".join(map(str, cleaned_confidence))\n",
    "\n",
    "\n",
    "\n",
    "# Dictionary to store processed data\n",
    "dent_data = {}\n",
    "\n",
    "for sheet_name, df in data_dict.items():\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tooth = row.get(\"Tooth\", \"\")  # Safely get 'Tooth' column value\n",
    "\n",
    "        # Process and clean Value/Confidence pairs\n",
    "        upper_value, upper_confidence = clean_values_confidence(row.get(\"Upper Value\"), row.get(\"Upper Confidence\"))\n",
    "        central_value, central_confidence = clean_values_confidence(row.get(\"Central Value\"), row.get(\"Central Confidence\"))\n",
    "        lower_value, lower_confidence = clean_values_confidence(row.get(\"Lower Value\"), row.get(\"Lower Confidence\"))\n",
    "\n",
    "        # Append cleaned row\n",
    "        new_rows.append([\n",
    "            tooth, upper_value, upper_confidence, central_value, central_confidence, lower_value, lower_confidence\n",
    "        ])\n",
    "\n",
    "    # Convert cleaned data to DataFrame\n",
    "    processed_df = pd.DataFrame(new_rows, columns=[\n",
    "        \"Tooth\", \"Upper Value\", \"Upper Confidence\", \"Central Value\",\n",
    "        \"Central Confidence\", \"Lower Value\", \"Lower Confidence\"\n",
    "    ])\n",
    "    \n",
    "    # Store processed DataFrame\n",
    "    dent_data[sheet_name] = processed_df\n",
    "\n",
    "    print(f\"Processed sheet: {sheet_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A1, B2', '0.9, 0.2')\n",
      "('C3', '0.6')\n",
      "('A1, D1, C1', '0.9, 0.8, 0.7')\n"
     ]
    }
   ],
   "source": [
    "print(clean_values_confidence(\"A1, , B2\", \"0.9, 0.5, 0.2\"))\n",
    "print(clean_values_confidence(\" , C3, \", \"0.7, 0.6, 0.0\"))\n",
    "print(clean_values_confidence(\"D1, C1, A1\", \"0.8, 0.7, 0.9\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet: MariaTejada\n",
      "       Tooth             Upper Value        Upper Confidence      Central Value      Central Confidence      Lower Value        Lower Confidence  \n",
      "          A1                C1, D2              0.3, 0.2              A1, B1              0.9, 0.1              C1, B1              0.2, 0.1      \n",
      "          A2                C3, C2              0.5, 0.2                  A2                   0.9                  D2                   0.3      \n",
      "          A3                    D4                   0.5                  A3                   0.9                  C2                   0.5      \n",
      "        A3_5                    A4                   0.2                A3_5                   0.7                  A4                   0.2      \n",
      "          A4                    C4                   0.2                  A4                   0.9                  C4                   0.4      \n"
     ]
    }
   ],
   "source": [
    "# Increase column spacing for better readability\n",
    "pd.set_option(\"display.colheader_justify\", \"center\")  # Center column headers\n",
    "pd.set_option(\"display.width\", 200)  # Increase display width\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "\n",
    "for sheet_name, df in dent_data.items():\n",
    "    print(f\"\\nSheet: {sheet_name}\")\n",
    "    print(df.head().to_string(index=False, col_space=20))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results from PyFCS (Option 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse values from string to a list of tuples\n",
    "def parse_values(cell):\n",
    "    if isinstance(cell, str):\n",
    "        try:\n",
    "            return eval(cell)  # Converts string representation of a list into an actual list\n",
    "        except (SyntaxError, NameError):\n",
    "            return []  \n",
    "    return []\n",
    "\n",
    "# Function to safely parse dictionary-like strings\n",
    "def parse_values_2(cell):\n",
    "    if isinstance(cell, str):\n",
    "        try:\n",
    "            return ast.literal_eval(cell)  # Converts string representation of a dictionary into an actual dictionary\n",
    "        except (ValueError, SyntaxError):\n",
    "            return {}  \n",
    "    return {}\n",
    "\n",
    "# Function to process Excel files\n",
    "def process_excel(file_path, parse_func, sort_dict=False):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Rename and clean the 'Imagen' column to 'Tooth'\n",
    "    df.rename(columns={\"Imagen\": \"Tooth\"}, inplace=True)\n",
    "    df[\"Tooth\"] = df[\"Tooth\"].str.replace(\".png\", \"\", regex=False)\n",
    "\n",
    "    # Apply parsing function to relevant columns\n",
    "    df[\"top\"] = df[\"top\"].apply(parse_func)\n",
    "    df[\"middle\"] = df[\"middle\"].apply(parse_func)\n",
    "    df[\"bottom\"] = df[\"bottom\"].apply(parse_func)\n",
    "\n",
    "    # Define a function to format values based on data type\n",
    "    def format_values(data):\n",
    "        if isinstance(data, list):  # Handles list of tuples\n",
    "            return \", \".join([str(i[0]) for i in data])\n",
    "        elif isinstance(data, dict) and sort_dict:  # Handles dictionary sorting by values\n",
    "            return \", \".join(sorted(data.keys(), key=data.get, reverse=True))\n",
    "        return \"\"\n",
    "\n",
    "    def format_confidence(data):\n",
    "        if isinstance(data, list):  # Handles list of tuples\n",
    "            return \", \".join([str(i[1]) for i in data])\n",
    "        elif isinstance(data, dict) and sort_dict:  # Handles dictionary sorting by values\n",
    "            return \", \".join(map(str, sorted(data.values(), reverse=True)))\n",
    "        return \"\"\n",
    "\n",
    "    # Create new formatted columns\n",
    "    df[\"Upper Value\"] = df[\"top\"].apply(format_values)\n",
    "    df[\"Upper Confidence\"] = df[\"top\"].apply(format_confidence)\n",
    "    df[\"Central Value\"] = df[\"middle\"].apply(format_values)\n",
    "    df[\"Central Confidence\"] = df[\"middle\"].apply(format_confidence)\n",
    "    df[\"Lower Value\"] = df[\"bottom\"].apply(format_values)\n",
    "    df[\"Lower Confidence\"] = df[\"bottom\"].apply(format_confidence)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=[\"top\", \"middle\", \"bottom\"], inplace=True)\n",
    "\n",
    "    # Return the processed DataFrame with selected columns\n",
    "    return df[['Tooth', 'Upper Value', 'Upper Confidence', 'Central Value', \n",
    "               'Central Confidence', 'Lower Value', 'Lower Confidence']]\n",
    "\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "base_path = os.path.join(os.getcwd(), \"Results\", \"PyFCS\")\n",
    "file_1 = os.path.join(base_path, \"results_opt_1.xlsx\")\n",
    "file_2 = os.path.join(base_path, \"results_opt_2.xlsx\")\n",
    "\n",
    "# Process both files\n",
    "pyfcs_opt_1 = process_excel(file_1, parse_values)\n",
    "pyfcs_opt_2 = process_excel(file_2, parse_values_2, sort_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Tooth             Upper Value        Upper Confidence      Central Value      Central Confidence      Lower Value        Lower Confidence  \n",
      "          A1              A1, D2, C1       0.417, 0.334, 0.15                A1                     1.0            D2, A1            0.475, 0.306 \n",
      "          A2              C3, C4, A3      0.219, 0.205, 0.179            A2, B2            0.666, 0.319        B2, D3, C4       0.4, 0.296, 0.148 \n",
      "          A3              D4, C3, C4      0.331, 0.285, 0.229            A3, B2             0.83, 0.103        D4, C2, C4     0.282, 0.282, 0.227 \n",
      "        A3_5                  B4, C4             0.435, 0.365      A3_5, B3, B4     0.421, 0.322, 0.245      C4, A3_5, B4     0.338, 0.272, 0.193 \n",
      "          A4              C4, A4, B4      0.546, 0.279, 0.101            A4, C3            0.711, 0.225            C4, A4            0.718, 0.254 \n",
      "\n",
      "\n",
      "       Tooth             Upper Value        Upper Confidence      Central Value      Central Confidence      Lower Value        Lower Confidence  \n",
      "          A1                      D2                      1.0                A1                     1.0               D2                      1.0 \n",
      "          A2                  C3, C2             0.631, 0.369            A2, B2            0.767, 0.233               D3                      1.0 \n",
      "          A3                      C3                      1.0                A3                     1.0       C3, C2, C4      0.764, 0.229, 0.007 \n",
      "        A3_5              A4, C4, C3      0.508, 0.358, 0.134      A3.5, B3, B4     0.594, 0.267, 0.139       C4, C3, A4      0.773, 0.114, 0.113 \n",
      "          A4                      C4                      1.0            A4, C3            0.799, 0.201               C4                      1.0 \n"
     ]
    }
   ],
   "source": [
    "print(pyfcs_opt_1.head().to_string(index=False, col_space=20))\n",
    "print(\"\\n\")\n",
    "print(pyfcs_opt_2.head().to_string(index=False, col_space=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of real results with cases solved by PyFCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matches(dent_data, pyfcs_opt_1, mode=0, sheet_name=None):\n",
    "    matches = {\"Upper Value\": 0, \"Central Value\": 0, \"Lower Value\": 0}\n",
    "    value_types = [\"Upper Value\", \"Central Value\", \"Lower Value\"]\n",
    "\n",
    "    # If a sheet is specified, only process that sheet\n",
    "    if sheet_name:\n",
    "        if sheet_name not in dent_data:\n",
    "            print(f\"Sheet '{sheet_name}' not found in dent_data.\")\n",
    "            return matches  # Return an empty dictionary if the sheet doesn't exist\n",
    "        dent_data = {sheet_name: dent_data[sheet_name]}  # Filter dent_data to keep only the selected sheet\n",
    "\n",
    "    # Iterate over the sheets (if there's only one, it will process only that)\n",
    "    for sheet_name, sheet_data in dent_data.items():\n",
    "        for i in range(len(sheet_data[\"Tooth\"])):\n",
    "            for value_type in value_types:\n",
    "                # Extract values as sets\n",
    "                dent_values = set(sheet_data[value_type][i].split(\", \"))\n",
    "                pyfcs_values = set(pyfcs_opt_1[value_type][i].split(\", \"))\n",
    "\n",
    "                if mode == 0:  # General comparison (counts all matches)\n",
    "                    matches[value_type] += len(dent_values & pyfcs_values)\n",
    "\n",
    "                elif mode == 1:  # Boolean comparison (adds 1 if there's at least one match)\n",
    "                    if dent_values & pyfcs_values:\n",
    "                        matches[value_type] += 1\n",
    "\n",
    "                elif mode == 2:  # Highest confidence comparison (compares only the first value)\n",
    "                    if sheet_data[value_type][i].split(\", \")[0] == pyfcs_opt_1[value_type][i].split(\", \")[0]:\n",
    "                        matches[value_type] += 1\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Option Summary of pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MariaTejada'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dent_index = 0\n",
    "dent_key = list(dent_data.keys())[dent_index]\n",
    "dent_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches per row:\n",
      "\tUpper Value: 14\n",
      "\tCentral Value: 16\n",
      "\tLower Value: 12\n",
      "\n",
      "\n",
      "Matches with highest confidence:\n",
      "\tUpper Value: 8\n",
      "\tCentral Value: 15\n",
      "\tLower Value: 9\n",
      "\n",
      "\n",
      "Matches in total:\n",
      "\tUpper Value: 18\n",
      "\tCentral Value: 18\n",
      "\tLower Value: 13\n"
     ]
    }
   ],
   "source": [
    "matches_count = calculate_matches(dent_data, pyfcs_opt_1, mode=0, sheet_name=dent_key)  # To count matches\n",
    "matches_exist = calculate_matches(dent_data, pyfcs_opt_1, mode=1, sheet_name=dent_key)  # To check existence of matches\n",
    "matches_highest_confidence = calculate_matches(dent_data, pyfcs_opt_1, mode=2, sheet_name=dent_key) # Highest confidence comparison\n",
    "\n",
    "print(\"Matches per row:\")\n",
    "for col, match in matches_exist.items():\n",
    "    print(f\"\\t{col}: {match}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Matches with highest confidence:\")\n",
    "for col, match in matches_highest_confidence.items():\n",
    "    print(f\"\\t{col}: {match}\")\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "print(\"Matches in total:\")\n",
    "for col, match in matches_count.items():\n",
    "    print(f\"\\t{col}: {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Option Mean of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches per row:\n",
      "\tUpper Value: 14\n",
      "\tCentral Value: 15\n",
      "\tLower Value: 8\n",
      "\n",
      "\n",
      "Matches with highest confidence:\n",
      "\tUpper Value: 8\n",
      "\tCentral Value: 14\n",
      "\tLower Value: 2\n",
      "\n",
      "\n",
      "Matches in total:\n",
      "\tUpper Value: 17\n",
      "\tCentral Value: 17\n",
      "\tLower Value: 8\n"
     ]
    }
   ],
   "source": [
    "matches_count = calculate_matches(dent_data, pyfcs_opt_2, mode=0, sheet_name=dent_key)  # To count matches\n",
    "matches_exist = calculate_matches(dent_data, pyfcs_opt_2, mode=1, sheet_name=dent_key)  # To check existence of matches\n",
    "matches_highest_confidence = calculate_matches(dent_data, pyfcs_opt_2, mode=2, sheet_name=dent_key) # Highest confidence comparison\n",
    "\n",
    "print(\"Matches per row:\")\n",
    "for col, match in matches_exist.items():\n",
    "    print(f\"\\t{col}: {match}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Matches with highest confidence:\")\n",
    "for col, match in matches_highest_confidence.items():\n",
    "    print(f\"\\t{col}: {match}\")\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "print(\"Matches in total:\")\n",
    "for col, match in matches_count.items():\n",
    "    print(f\"\\t{col}: {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sheets: ['MariaTejada_Time']\n"
     ]
    }
   ],
   "source": [
    "# Define the Excel file path\n",
    "file_path = os.path.join(os.getcwd(), \"Results\", \"Val_Time.xlsx\")\n",
    "\n",
    "# Load all sheets into a dictionary\n",
    "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Convert each sheet into a DataFrame and store it in a dictionary\n",
    "data_dict = {name: df for name, df in sheets_dict.items()}\n",
    "\n",
    "# Display the loaded sheet names\n",
    "print(f\"Loaded sheets: {list(data_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: MariaTejada_Time\n",
      "Total Time: 52.69397112131119 minutos\n",
      "Top 5 dientes con más tiempo:\n",
      "  Diente: D3, Tiempo: 5.42 minutos\n",
      "  Diente: D2, Tiempo: 5.25 minutos\n",
      "  Diente: B3, Tiempo: 4.89 minutos\n",
      "  Diente: A2, Tiempo: 4.77 minutos\n",
      "  Diente: C3, Tiempo: 4.39 minutos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_tooth_times = {}\n",
    "for key, df in data_dict.items():\n",
    "    top_t = df[df['Tooth'] != 'Total'].sort_values(by='Elapsed Time (minutes)', ascending=False).head(5)\n",
    "    \n",
    "    # Get total time and top tooth in time\n",
    "    total_time = df[df['Tooth'] == 'Total']['Elapsed Time (minutes)'].iloc[0]\n",
    "    top_tooth_times[key] = {\n",
    "        'total_time': total_time,\n",
    "        'top_5_tooth': top_t[['Tooth', 'Elapsed Time (minutes)']].values.tolist()\n",
    "    }\n",
    "\n",
    "# Show Time Results\n",
    "for key, value in top_tooth_times.items():\n",
    "    print(f\"Sheet: {key}\")\n",
    "    print(f\"Total Time: {value['total_time']} minutos\")\n",
    "    print(\"Top 5 dientes con más tiempo:\")\n",
    "    for tooth, time in value['top_5_tooth']:\n",
    "        print(f\"  Diente: {tooth}, Tiempo: {time:.2f} minutos\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
