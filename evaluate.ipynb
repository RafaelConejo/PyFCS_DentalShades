{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = os.getcwd()  # Obtiene el directorio de trabajo actual\n",
    "pyfcs_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "\n",
    "# Add the PyFCS path to sys.path\n",
    "sys.path.append(pyfcs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 1. Software Validación Humana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero diccionario con el excel que contiene los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hojas cargadas: ['MariaTejada']\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo de Excel\n",
    "file_path = os.path.join(os.getcwd(), \"Results\", \"Val_Results.xlsx\")\n",
    "\n",
    "# Cargar todas las hojas en un diccionario\n",
    "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Convertir cada hoja en una matriz y almacenarla en un diccionario\n",
    "data_dict = {sheet_name: df for sheet_name, df in sheets_dict.items()}\n",
    "\n",
    "# Mostrar los nombres de las hojas cargadas\n",
    "print(f\"Hojas cargadas: {list(data_dict.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesado de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesada hoja: MariaTejada\n"
     ]
    }
   ],
   "source": [
    "def clean_values_confidence(values, confidence):\n",
    "    values_list = [v.strip() for v in str(values).split(\",\")]\n",
    "    confidence_list = [float(c) for c in str(confidence).split(\",\")]\n",
    "\n",
    "    # Asegurar que tengan el mismo tamaño agregando vacíos si falta alguno\n",
    "    while len(values_list) < len(confidence_list):\n",
    "        values_list.append(\"\")\n",
    "    while len(confidence_list) < len(values_list):\n",
    "        confidence_list.append(0.0)\n",
    "\n",
    "    # Filtrar solo las posiciones donde Value NO está vacío y Confidence > 0\n",
    "    cleaned_pairs = [(v, c) for v, c in zip(values_list, confidence_list) if v and c > 0]\n",
    "\n",
    "    # Separar en listas nuevamente\n",
    "    cleaned_values = [v for v, c in cleaned_pairs]\n",
    "    cleaned_confidence = [c for v, c in cleaned_pairs]\n",
    "\n",
    "    return \", \".join(cleaned_values), \", \".join(map(str, cleaned_confidence))\n",
    "\n",
    "\n",
    "\n",
    "# Diccionario donde guardaremos los datos procesados\n",
    "dent_data = {}\n",
    "for sheet_name, df in data_dict.items():\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():  # Iterar sobre cada fila\n",
    "        tooth = row['Tooth']  # Mantener la columna 'Tooth'\n",
    "\n",
    "        # Procesar todas las combinaciones de Value/Confidence\n",
    "        upper_value, upper_confidence = clean_values_confidence(row['Upper Value'], row['Upper Confidence'])\n",
    "        central_value, central_confidence = clean_values_confidence(row['Central Value'], row['Central Confidence'])\n",
    "        lower_value, lower_confidence = clean_values_confidence(row['Lower Value'], row['Lower Confidence'])\n",
    "\n",
    "        # Crear nueva fila con datos procesados\n",
    "        new_rows.append([tooth, upper_value, upper_confidence, central_value, central_confidence, lower_value, lower_confidence])\n",
    "\n",
    "    # Convertir la lista de filas procesadas a un DataFrame\n",
    "    processed_df = pd.DataFrame(new_rows, columns=[\n",
    "        'Tooth', 'Upper Value', 'Upper Confidence', 'Central Value', 'Central Confidence', 'Lower Value', 'Lower Confidence'\n",
    "    ])\n",
    "    dent_data[sheet_name] = processed_df\n",
    "\n",
    "    print(f\"Procesada hoja: {sheet_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A1, B2', '0.9, 0.2')\n",
      "('C3', '0.6')\n"
     ]
    }
   ],
   "source": [
    "print(clean_values_confidence(\"A1, , B2\", \"0.9, 0.5, 0.2\"))\n",
    "print(clean_values_confidence(\" , C3, \", \"0.7, 0.6, 0.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hoja: MariaTejada\n",
      "Tooth Upper Value Upper Confidence Central Value Central Confidence Lower Value Lower Confidence\n",
      "   A1      C1, D2         0.3, 0.2        A1, B1           0.9, 0.1      C1, B1         0.2, 0.1\n",
      "   A2      C3, C2         0.5, 0.2            A2                0.9          D2              0.3\n",
      "   A3          D4              0.5            A3                0.9          C2              0.5\n",
      " A3_5          A4              0.2          A3_5                0.7          A4              0.2\n",
      "   A4          C4              0.2            A4                0.9          C4              0.4\n"
     ]
    }
   ],
   "source": [
    "for sheet_name, df in dent_data.items():\n",
    "    print(f\"\\nHoja: {sheet_name}\")\n",
    "    print(df.head().to_string(index=False))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de ambos resultados de PyFCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tooth Upper Value    Upper Confidence Central Value  Central Confidence  Lower Value    Lower Confidence\n",
      "   A1  A1, D2, C1  0.417, 0.334, 0.15    A1, B1, D2       1.0, 0.0, 0.0   D2, A1, C4 0.475, 0.306, 0.096\n",
      "   A2  C3, C4, A3 0.219, 0.205, 0.179    A2, B2, A3 0.666, 0.319, 0.008   B2, D3, C4   0.4, 0.296, 0.148\n",
      "   A3  D4, C3, C4 0.331, 0.285, 0.229    A3, B2, D4  0.83, 0.103, 0.049   D4, C2, C4 0.282, 0.282, 0.227\n",
      " A3_5  B4, C4, A4 0.435, 0.365, 0.097  A3.5, B3, B4 0.421, 0.322, 0.245 C4, A3.5, B4 0.338, 0.272, 0.193\n",
      "   A4  C4, A4, B4 0.546, 0.279, 0.101  A4, C3, A3.5 0.711, 0.225, 0.062   C4, A4, C3 0.718, 0.254, 0.018\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Función para analizar los valores\n",
    "def parse_values(cell):\n",
    "    if isinstance(cell, str):\n",
    "        return eval(cell)  # Convierte la cadena en una lista de tuplas\n",
    "    return []\n",
    "\n",
    "# Función para dividir los valores por columna\n",
    "def split_values(df, col):\n",
    "    return df[col].str.split(', ').apply(lambda x: x)\n",
    "\n",
    "# Leer el archivo Excel\n",
    "file_path = os.path.join(os.getcwd(), \"Results\", \"PyFCS\", \"results_opt_1.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Eliminar la extensión .png de la columna Imagen y renombrarla a Tooth\n",
    "df = df.rename(columns={\"image\": \"Tooth\"})\n",
    "df[\"Tooth\"] = df[\"Tooth\"].str.replace(\".png\", \"\", regex=False)\n",
    "\n",
    "# Aplicar la función parse_values a las columnas 'top', 'middle', 'bottom'\n",
    "df[\"top\"] = df[\"top\"].apply(parse_values)\n",
    "df[\"middle\"] = df[\"middle\"].apply(parse_values)\n",
    "df[\"bottom\"] = df[\"bottom\"].apply(parse_values)\n",
    "\n",
    "# Crear nuevas columnas para el formato requerido\n",
    "df[\"Upper Value\"] = df[\"top\"].apply(lambda x: \", \".join([i[0] for i in x]))\n",
    "df[\"Upper Confidence\"] = df[\"top\"].apply(lambda x: \", \".join([str(i[1]) for i in x]))\n",
    "df[\"Central Value\"] = df[\"middle\"].apply(lambda x: \", \".join([i[0] for i in x]))\n",
    "df[\"Central Confidence\"] = df[\"middle\"].apply(lambda x: \", \".join([str(i[1]) for i in x]))\n",
    "df[\"Lower Value\"] = df[\"bottom\"].apply(lambda x: \", \".join([i[0] for i in x]))\n",
    "df[\"Lower Confidence\"] = df[\"bottom\"].apply(lambda x: \", \".join([str(i[1]) for i in x]))\n",
    "\n",
    "# Eliminar las columnas 'top', 'middle', 'bottom'\n",
    "df = df.drop(columns=[\"top\", \"middle\", \"bottom\"])\n",
    "\n",
    "# Ahora, tenemos la estructura que buscas.\n",
    "# Solo necesitamos el DataFrame resultante con las columnas organizadas.\n",
    "pyfcs_opt_1 = df[['Tooth', 'Upper Value', 'Upper Confidence', 'Central Value', \n",
    "                'Central Confidence', 'Lower Value', 'Lower Confidence']]\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(pyfcs_opt_1.head().to_string(index=False))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': {'Upper Value': 'A1, D2, C1',\n",
       "  'Upper Confidence': '0.417, 0.334, 0.15',\n",
       "  'Central Value': 'A1, B1, D2',\n",
       "  'Central Confidence': '1.0, 0.0, 0.0',\n",
       "  'Lower Value': 'D2, A1, C4',\n",
       "  'Lower Confidence': '0.475, 0.306, 0.096'},\n",
       " 'A2': {'Upper Value': 'C3, C4, A3',\n",
       "  'Upper Confidence': '0.219, 0.205, 0.179',\n",
       "  'Central Value': 'A2, B2, A3',\n",
       "  'Central Confidence': '0.666, 0.319, 0.008',\n",
       "  'Lower Value': 'B2, D3, C4',\n",
       "  'Lower Confidence': '0.4, 0.296, 0.148'},\n",
       " 'A3': {'Upper Value': 'D4, C3, C4',\n",
       "  'Upper Confidence': '0.331, 0.285, 0.229',\n",
       "  'Central Value': 'A3, B2, D4',\n",
       "  'Central Confidence': '0.83, 0.103, 0.049',\n",
       "  'Lower Value': 'D4, C2, C4',\n",
       "  'Lower Confidence': '0.282, 0.282, 0.227'},\n",
       " 'A3_5': {'Upper Value': 'B4, C4, A4',\n",
       "  'Upper Confidence': '0.435, 0.365, 0.097',\n",
       "  'Central Value': 'A3.5, B3, B4',\n",
       "  'Central Confidence': '0.421, 0.322, 0.245',\n",
       "  'Lower Value': 'C4, A3.5, B4',\n",
       "  'Lower Confidence': '0.338, 0.272, 0.193'},\n",
       " 'A4': {'Upper Value': 'C4, A4, B4',\n",
       "  'Upper Confidence': '0.546, 0.279, 0.101',\n",
       "  'Central Value': 'A4, C3, A3.5',\n",
       "  'Central Confidence': '0.711, 0.225, 0.062',\n",
       "  'Lower Value': 'C4, A4, C3',\n",
       "  'Lower Confidence': '0.718, 0.254, 0.018'},\n",
       " 'B1': {'Upper Value': 'D2, B1, A1',\n",
       "  'Upper Confidence': '0.54, 0.301, 0.07',\n",
       "  'Central Value': 'B1, A1, D2',\n",
       "  'Central Confidence': '0.992, 0.007, 0.0',\n",
       "  'Lower Value': 'B1, D2, C4',\n",
       "  'Lower Confidence': '0.504, 0.413, 0.066'},\n",
       " 'B2': {'Upper Value': 'C2, B2, D3',\n",
       "  'Upper Confidence': '0.361, 0.255, 0.166',\n",
       "  'Central Value': 'B2, C1, A2',\n",
       "  'Central Confidence': '0.934, 0.057, 0.006',\n",
       "  'Lower Value': 'C1, D3, C4',\n",
       "  'Lower Confidence': '0.291, 0.286, 0.218'},\n",
       " 'B3': {'Upper Value': 'B4, C4, B3',\n",
       "  'Upper Confidence': '0.378, 0.238, 0.167',\n",
       "  'Central Value': 'B3, B4, A3',\n",
       "  'Central Confidence': '0.982, 0.016, 0.001',\n",
       "  'Lower Value': 'C4, B3, C3',\n",
       "  'Lower Confidence': '0.276, 0.231, 0.199'},\n",
       " 'B4': {'Upper Value': 'B4, C4, A4',\n",
       "  'Upper Confidence': '0.643, 0.254, 0.043',\n",
       "  'Central Value': 'B4, B3, A3.5',\n",
       "  'Central Confidence': '0.964, 0.035, 0.001',\n",
       "  'Lower Value': 'B4, C4, C3',\n",
       "  'Lower Confidence': '0.513, 0.32, 0.098'},\n",
       " 'C1': {'Upper Value': 'D3, C1, C4',\n",
       "  'Upper Confidence': '0.429, 0.3, 0.215',\n",
       "  'Central Value': 'C1, D2, B2',\n",
       "  'Central Confidence': '0.967, 0.017, 0.014',\n",
       "  'Lower Value': 'D3, C1, D2',\n",
       "  'Lower Confidence': '0.304, 0.268, 0.225'},\n",
       " 'C2': {'Upper Value': 'C4, C3, C2',\n",
       "  'Upper Confidence': '0.395, 0.324, 0.19',\n",
       "  'Central Value': 'C2, D4, B2',\n",
       "  'Central Confidence': '0.954, 0.038, 0.007',\n",
       "  'Lower Value': 'C2, C4, C3',\n",
       "  'Lower Confidence': '0.501, 0.308, 0.135'},\n",
       " 'C3': {'Upper Value': 'C4, C3, D4',\n",
       "  'Upper Confidence': '0.537, 0.353, 0.039',\n",
       "  'Central Value': 'C3, D4, C2',\n",
       "  'Central Confidence': '0.587, 0.377, 0.035',\n",
       "  'Lower Value': 'C3, C4, D4',\n",
       "  'Lower Confidence': '0.53, 0.453, 0.005'},\n",
       " 'C4': {'Upper Value': 'C4, A4, B4',\n",
       "  'Upper Confidence': '0.906, 0.083, 0.002',\n",
       "  'Central Value': 'C4, A4, C3',\n",
       "  'Central Confidence': '0.957, 0.041, 0.002',\n",
       "  'Lower Value': 'C4',\n",
       "  'Lower Confidence': '0.989'},\n",
       " 'D2': {'Upper Value': 'C4, D3, C3',\n",
       "  'Upper Confidence': '0.319, 0.251, 0.166',\n",
       "  'Central Value': 'D2, C1, D3',\n",
       "  'Central Confidence': '0.719, 0.279, 0.001',\n",
       "  'Lower Value': 'D2, D3, C4',\n",
       "  'Lower Confidence': '0.44, 0.289, 0.249'},\n",
       " 'D3': {'Upper Value': 'D3, C4, C3',\n",
       "  'Upper Confidence': '0.327, 0.323, 0.207',\n",
       "  'Central Value': 'D3, C2, C1',\n",
       "  'Central Confidence': '0.606, 0.297, 0.077',\n",
       "  'Lower Value': 'D3, C4, C2',\n",
       "  'Lower Confidence': '0.408, 0.336, 0.214'},\n",
       " 'D4': {'Upper Value': 'C3, C4, D4',\n",
       "  'Upper Confidence': '0.365, 0.256, 0.19',\n",
       "  'Central Value': 'D4, C2, B3',\n",
       "  'Central Confidence': '0.903, 0.055, 0.021',\n",
       "  'Lower Value': 'C3, C4, D4',\n",
       "  'Lower Confidence': '0.43, 0.335, 0.18'}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
